%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                 %
%%%%%     <file_name>.tex                                             %
%%%%%                                                                 %
%%%%% Author:      <author>                                           %
%%%%% Created:     <date>                                             %
%%%%% Description: <description>                                      %
%%%%%                                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}

    Thanks to the smaller nodes of modern lithography technologies and the transistor density we can achieve with them, modern low-power \glspl{cpu} can have a large amount of cores while keeping their power consumption under a few Watts. A single Raspberry Pi 3 has a peak performance of 6 \si{gflop/s} for a power consumption of only 7 Watts~\cite{Art:RpiClusters}.
    Embedded systems can take advantage of this increase in efficiency to become more autonomous and not rely on an external computer for heavy computation. We can find this type of architecture on some nano drones such as the CrazyFlie 2.0~\cite{Web:CrazyFlie20}, which can be extended with additional shields. Using a custom shield, the \gls{iis} of \gls{eth} achieved to analyze in real-time a video signal and train a neural network for autonomous navigation~\cite{Art:NanoDrone}. The compute unit achieved a rate of 281 \si{MMAC/s} on a power-enveloppe of only 45 \si{mW}.

    To improve the energy efficiency and the computing power of \gls{ulp} systems, new architectures are needed. To keep the power consumption low, an embedded system needs to power it's subsystems only when needed. The CrazyFlie uses a low power ARM Cortex-M4 to manage the flight of the drone, and can power on and of it's extension board as needed. The shield use a \gls{pulp} cluster, which is an \gls{riscv} \gls{soc} which can be configured with up to eight cores. With this configuration, the energy consumption of the CrazyFlie stays low, as most of the time it only uses the micro controller to flight and only power on the shield for the heavy computation.

	Heterogeneous systems are composed of multiple coprocessors all managed by a host processor. This architecture is interesting when it comes to embedded systems, as it is possible to achive greater energy efficiency than homogeneous systems. If each coprocessor has been designed to solve a certain task, it can achieve energy efficiency than a general purpose \gls{cpu}. 
	In this article~\cite{Art:Harnessing} pusblished by the University of California,  researchers showed that under heavy design constraints (such as die area or therman dissipation), systems using multiple \glspl{isa} achieved better performances than their best homogeneous counterpart.

This strategy has been used in the \gls{soc} industry by ARM since 2011~\cite{Art:bigLITTLE}. The  big.LITTLE architecture is based on two clusters of ARM Cortex A7(the ``LITTLE''cores) and A15 (the ``big'' cores), and was designed to increase the computing power in low power systems such as smartphones while increasing the battery life of the device. This architecture relied on a single~ \gls{isa}(ARMv7). The goal was to use the more powerful cores during heavy computation or graphic rendering, and let the low power cores handle the background tasks or manage the device during sleep.
	Presently, every smartphone \gls{soc} manufacturer use the bigLITTLE architecture or a similar technology.


Even in data centers, where power consumption is also an issue, \glspl{gpu} are used thanks to their massive core count and the various \glspl{api} such as \gls{cuda} or \gls{opencl} which simplify the developement process for \gls{gpu} accelerators.

    \gls{hero}~\cite{Art:Hero} is a heterogeneous system developed by the \gls{iis} of \acrshort{eth} and the \gls{eees} of the University of Bologna.
	This platform is composed of a hard macro ARM 64 \gls{cpu} and up to eight \gls{pulp} clusters(\gls{riscv} cores) running on an Xilinx ZYNC ZC706 \gls{fpga}.

    This platform is designed to ``facilitate rapid exploration on all software and hardware layers''~\cite{Art:Hero}, and includes a heterogeneous compilation toolchain with support for \gls{openmp}, an \gls{api} developed to make developement of multi threaded applications easier~\cite{Web:Wikipedia_OpenMP}. This \gls{api} implements new preprocessor instructions to tell the compiler how to execute the code on the system.



\section {Design Issue with heterogeneous systems}

    During their conception, numerous design choices need to be made specifically how the \glspl{cpu} in the system will interact will each other. These choices will impact the peak performance of the design or its power consumption~\cite{Art:Harnessing}. The computer architect has to choose how the different \glspl{pcma} will interact, how they will share data, maybe extend the existing \glspl{isa} to distribute tasks, and so on.
    The software design is challenging, when compiling for heterogeneous platforms. The compiler needs to create an executable that will run on the host processor, but also dedicate parts of the final binary to embed the code that will be distributed on the \glspl{pcma}.
	Code distribution is handled by the programmer, \glspl{api} such as \gls{cuda}, \gls{opencl} or \gls{openmp} using function calls tell the compiler how to execute the code and on which \gls{pcma}. 
	Even though these \gls{api} did a great job at making the overall developpement easier, most of the work is still done by hand. The programmer has to handle memory mapping (will the data be stored on the host or the \gls{pcma} memory), every task needs to be scheduled by hand, and distributed on the correct \gls{pcma}. 
	Moreover, the code is often not portable as some schedule are target dependant. An algorithm coded with \gls{cuda} will only run on a \gls{gpu}, so the code can't be reused for another platform.
	Porting \gls{api} to new platform is not trivial, and require sometime months of work, to make the \gls{api} run on the new target.





\section {Currently Available Workflow for \acrshort{hero}}
    Currently, \gls{hero} supports \gls{openmp}~\cite{Report:SoftwareStack}, an \gls{api} which ``defines a portable, scalable model with a simple and flexible interface for developing parallel applications on platforms from the desktop to the supercomputer''~\cite{Web:OpenMp}. 
	This \gls{api} has been implemented on \gls{hero} to easily take advantage of the \gls{pulp} clusters. The toolchain uses the Clang compiler~\cite{Web:Wikipedia_OpenMP} to compile the applications. \gls{hero} uses custom Clang front ends to supports all the available configurations (only the \gls{pulp} cluster for simulation with the ARM host \gls{cpu} or with a 64 bits \gls{riscv} \gls{cpu}).

    To distribute the code, \gls{openmp} uses preprocessor instructions to tell Clang where the code will run and how it will be executed. Exploring the design space using \gls{openmp}'s directive can be time-consuming. For example, the developer must explicitly tell which part of the code to offload. Trying to change the order of multiple loops may cause bugs in the algorithmn, and complex schedules often impact code readability making them harder to debug

    Halide~\cite{Art:Halide} was proposed to explore the idea of separating the algorithm from how the code will be executed on the target(the schedule).
    This separation makes testing different schedule easier on the developer, as the algorithm code will stay the same, and only the scheduling will be changed when testing.
    Every processing pipeline designed with Halide has two parts. The first part consists of the functional description of the processing kernel, i.e. the algorithm that will be executed. 
	The second part is the schedule of the pipeline. The programer will explicitely tell Halide how the pipeline should be executed. Thanks to specific function calls, the developer can decide whether the code will be run on multiple threads or a single one, change the order of execution of different parts, split loops, unrolls them. The developer can still have the freedom to implement any schedule he wants but without having to change the main algorithm.
    This programming model is interesting because the developer can quicky implement the algorithm without having to take into account the boundaries of the inputs, and then work on an optimal schedule, or quickly adapt it if the algorithm need to be executed on another platform.

    The intermediate variables can be bounded afterwards if needed, and the pricipal variables such as characteristics of the inputs are automatically bounded by Halide. An image processing pipeline will only compute the output on the pixels of the input.
    The scheduling process can even be done automatically during the compilation by the library, in order to find an optimal schedule on the target platform.

%%%%%%%%% GOAL OF THE PROJECT
	The goal of this project was to port Halide to \gls{hero}, and execute image processing kernels on the \gls{hero} system running on an \gls{fpga}. First Halide needs to be compiled to support \gls{riscv} and compile basic applications to the hardware simulation. From then we can work on the heterogeneous compilation to support the current \gls{hero} test platform.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../report_template"
%%% End: 
