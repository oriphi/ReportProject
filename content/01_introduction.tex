%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                 %
%%%%%     <file_name>.tex                                             %
%%%%%                                                                 %
%%%%% Author:      <author>                                           %
%%%%% Created:     <date>                                             %
%%%%% Description: <description>                                      %
%%%%%                                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}

\section{Heterogeneous systems}

    Thanks to system integration and the better energy efficiency of modern \gls{cpu}, embedded systems are becoming quite powerful. They can now manage multiple sensors in real-time. But the power consumption is still an issue. These chips often have a limited power budget as their goal is to be embedded in small systems where the battery capacity doesn't exceed the hundreds of milli Ampere hour. 


    To improve the energy efficiency and the computing power of those chips, researchers have been trying to find new architecture which would suit those applications. Heterogeneous computing may be one of the solutions to this problem. Heterogeneous systems are often composed of one general-purpose~\gls{cpu} and multiple coprocessors which will be used to handle specific tasks~\cite{Art:HeteroStrat}. This strategy has been used in the SoC industry by ARM since 2011 by ARM in it's big.LITTLE architecture~\cite{Art:bigLITTLE}. This architecture based on two clusters of ARM Cortex A7 and A15, was designed to increase the computing power in embedded systems such as smartphones while increasing the battery life of the device. Even though this architecture relied on a single~ \gls{isa}, the idea was to use more powerful cores when needed and turn them off when the device was in sleep mode or when the lower power core could handle the task. 


	These architectures are interesting to increase the power efficiency but can also increase the processing power at the same time. Researchers have been trying to take advantage of multiple \gls{isa} and leverage their specificities to increase the overall performances with great success. In this article~\cite{Art:Harnessing} from 2014, researchers compared homogeneous and heterogeneous systems based on three \gls{isa}, under strict design constraint (such as area or thermal dissipation) they observed that the heterogeneous designs performed better than their homogeneous counterpart. Heterogeneous systems are also heavily used in Data Centers, as the processing needs keep rising, they now use GPU as they are heavily optimized for parallel tasks and are now powerful enough to be used in scientific applications.

    Hero~\cite{Art:Hero} is a heterogeneous system developed by the \gls{iis} and the \gls{eees}. This platform is composed of a hard multicore ARM 64 Juno \gls{soc} (composed of two Cortex A57 and four Cortex A553) and up to eight \gls{pulp} clusters (composed of eight RI5CY cores), running on an \gls{fpga}.

\section {Design Issue with heterogeneous systems}
	Due to their heterogeneous nature, those systems are difficult to design and program. During their conception, numerous design choices needs to be made to make sure that all the \gls{cpu} in the system will interact will each other, these choices will impact the peak performance of the design or it's power consumption~\cite{Art:Harnessing}. The architect has to choose how  the different accelerators will interact, how they will share data, maybe extend the existing \gls{isa} to distribute tasks and so on.

	The software design isn't easy either, when compiling for such systems, the compiler needs to create an executable that will run on the host processor, but also integrate instructions that will be run on the coprocessors. Most of the time, the programmer assign which part of the code will run on which accelerator, OpenMp uses this model via the \verb|#pragma| preprocessor instructions. Then during the compilation, llvm will compile the code bits to the right platform and link them using the adequate linker.



\section {Currently Available Workflow for Halide}
	Currently Hero supports OpenMp, which is an \gls{api}which ``defines a portable, scalable model with a simple and flexible interface for developing parallel applications on platforms from the desktop to the supercomputer''~\cite{Web:OpenMp}. This API has been implemented on hero to easily take advantage of the clusters. The toolchain uses clang, and the clang-offload-bundler to compile the applications. Clang uses a custom front head for hero which support all the available configurations for hero (only the pulp cluster for simulation, with the ARM \gls{cpu} as the host for the \gls{fpga} or with a riscV 64 bits \gls{cpu}).

	Exploring the design space using OpenMp's directive isn't perfect, and require the developer to adapt its code to run with a specific schedule, for example, to take advantage of vectorization, the programmer has to manually unroll the loops and change it's code so that the compiler knows what part of the code will be using the \gls{simd} instructions. This approach leads to an important development time but also an extensive testing process whenever the schedule is changed to ensure that the resulting code works as intended. This approach makes testing for new schedule pretty difficult and inefficient. 

	Starting from this idea that separating the algorithm from how it is run, researchers from the \gls{mit}, created Halide. 
    Halide~\cite{Art:Halide} is a programming language that was designed to allow the developer to explore multiple design choices quickly by separating the algorithm from the execution schedule. This language was designed to be used in image or array processing applications.
    Every processing pipeline designed with Halide has two parts. The first part consist of the functional description of the processing kernel, this is the algorithm that will be executed on the array. The second part is the schedule of the pipeline. This schedule describes how the algorithm will be executed on the system. This programming model is interesting because the developer can implement the algorithm without having to take into account the boundaries of the functions or the border effects. Then he can quickly bound the different variables of the pipeline and design it's schedule afterward. All the constraints will be asserted during the compilation of the pipeline  without any intervention from the developer. The scheduling process can even be done automatically during the compilatio by the library, in order to find an orptimal schedule on the target platform.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../report_template"
%%% End: 
