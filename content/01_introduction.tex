%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%                                                                 %
%%%%%     <file_name>.tex                                             %
%%%%%                                                                 %
%%%%% Author:      <author>                                           %
%%%%% Created:     <date>                                             %
%%%%% Description: <description>                                      %
%%%%%                                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}

    Thanks to the smaller nodes of modern lithography technologies and the transistor density we can achieve with them, modern low-power \glspl{cpu} can have a large amount of cores while keeping their power consumption under a few Watts. A single Raspberry Pi 3 has a peak performance of 6 \si{gflop} for a power consumption of only 7 Watts~\cite{Art:RpiClusters}.
    Embedded systems can take advantage of this increase in efficiency to become more autonomous and not rely on an external computer for heavy computation. Nano drones can now analyze in real-time a video signal and train a neural network for autonomous navigation, at a rate of \si{281 MMAC/s} on a power-enveloppe of \si{45mW}~\cite{Art:NanoDrone}.

    To improve the energy efficiency and the computing power of \gls{ulp} systems, new architectures are needed. To keep the power consumption low, an embedded system needs to power it's subsystems only when needed. Autonomous drones~\cite{Art:NanoDrones} use a low-performance microcontroller to manage it coupled with a high-performance \gls{ulp} cluster of \gls{riscv} cores for signal processing. System composed by one host processor and one or multiple coprocessors are called heterogeneous systems, they are suited for embedded applications as they can keep a low power consumption while using high-performance accelerator when needed.

This strategy has been used in the \gls{soc} industry by ARM since 2011~\cite{Art:bigLITTLE}. The  big.LITTLE architecture is based on two clusters of ARM Cortex A7(the ``LITTLE''cores) and A15 (the ``big'' cores), and was designed to increase the computing power in low power systems such as smartphones while increasing the battery life of the device. This architecture relied on a single~ \gls{isa}(ARMv7). The goal was to use the more powerful cores during heavy computation or graphic rendering, and let the low power cores handle the background tasks or manage the device during sleep.


Researchers from the University of California~\cite{Art:Harnessing} tried to leverage the advantages of multiple \glspl{isa}. Under heavy design constraints (such as die area or thermal dissipation) heterogeneous systems based on multiple \glspl{isa} performed better than the best homogeneous counterpart (in terms of energy efficiency and compute performance). 


Even in data centers, where power consumption is also an issue, \glspl{gpu} are used thanks to their massive core count and the various \glspl{api} such as \gls{cuda} or \gls{opencl} whichc simplify the developement process for \gls{gpu} accelerators.
%% CHANGES

    \gls{hero}~\cite{Art:Hero} is a heterogeneous system developed by the \gls{iis} of \acrshort{eth} and the \gls{eees} of the University of Bologna. This platform is composed of a hard multicore ARM 64 Juno \gls{soc} (composed of two Cortex A57 and four Cortex A53 cores) and up to eight \gls{pulp} clusters (composed of eight RI5CY cores~\cite{Art:Hero}), running on an \gls{fpga}(a Xilinx ZYNC ZC706).
    The \gls{pulp} cluster is based on the \gls{riscv} \gls{isa}, an open source \gls{isa} designed to support a wide range of platform from embedded systems to supercomputer. The modularity of the \gls{isa} makes it interesting for \glspl{pcma}.

    This platform is designed to ``facilitate rapid exploration on all software and hardware layers''~\cite{Art:Hero}, and includes a heterogeneous compilation toolchain with support for \gls{openmp}, an \gls{api} developed to make developement of multi threaded aplications easier~\cite{Web:Wiki_OpenMP}. This \gls{api} implements new preprocessor instructions to tell the compiler how to execute the code on the system.



\section {Design Issue with heterogeneous systems}
    During their conception, numerous design choices need to be made specify how the \glspl{cpu} in the system will interact will each other. These choices will impact the peak performance of the design or its power consumption~\cite{Art:Harnessing}. The computer architect has to choose how the different \glspl{pcma} will interact, how they will share data, maybe extend the existing \glspl{isa} to distribute tasks, and so on.

    The software design is challenging, when compiling for heterogeneous platforms. The compiler needs to create an executable that will run on the host processor, but also dedicate parts of the final binary to embed the code that will be distributed on the \glspl{pcma}. Code distribution is handled by the programmer, \glspl{api} such as \gls{cuda}, \gls{opencl} or \gls{openmp} using function calls tell the compiler how to execute the code and on which \gls{pcma}.


\section {Currently Available Workflow for \gls{hero}}
    Currently, \gls{hero} supports \gls{openmp}~\cite{Report:SoftwareStack}, an \gls{api} which ``defines a portable, scalable model with a simple and flexible interface for developing parallel applications on platforms from the desktop to the supercomputer''~\cite{Web:OpenMp}. This \gls{api} has been implemented on \gls{hero} to easily take advantage of the \gls{pulp} clusters. The toolchain uses the Clang compiler~\cite{Web:Wikipedia_OpenMP} to compile the applications. \gls{hero} uses custom Clang front ends to supports all the available configurations (only the \gls{pulp} cluster for simulation, with the ARM host \gls{cpu}  with a 64 bits \gls{riscv} \gls{cpu}).

    To distribute the code, \gls{openmp} uses preprocessor instructions to tell Clang where the code will run and how it will be executed. Exploring the design space using \gls{openmp}'s directive can be time-consuming. For example, the developer must explicitly tell which part of the code to offload. Trying to change the order of multiple loops may cause bugs in the algorithmn, and complex schedules often impact code readability making them harder to debug

    Halide~\cite{Art:Halide} was proposed to explore the idea of separating the algorithm from the schedule.
    This separation makes testing different schedule easier on the developer, as the algorithm code will stay the same, and only the scheduling will be changed when testing.
    Every processing pipeline designed with Halide has two parts. The first part consists of the functional description of the processing kernel, i.e. the algorithm that will be executed. 
	The second part is the schedule of the pipeline. The programer will explicitely tell Halide how the pipeline should be executed. Thanks to specific function calls, the developer can decide whether the code will be run on multiple threads or a single one, change the order of execution of different parts, split loops, unrolls them. The developer can still has the freedom to implement any schedule he wants but without having to change the main algorithm.
    This programming model is interesting because the developer can quicky implement the algorithm without having to take into account the boundaries of the inputs, and then work on an optimal schedule.

    The intermediate variables can be bounded afterwards if needed, and the pricipal variables such as characteristics of the inputs are automatically bounded by Halide. An image processing pipeline will only compute the output on the pixels of the input.
    The scheduling process can even be done automatically during the compilation by the library, in order to find an optimal schedule on the target platform.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../report_template"
%%% End: 
